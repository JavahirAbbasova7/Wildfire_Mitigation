in_evaluation: false
sim_init_cfg:
  simfire_cls:
    _target_: hydra.utils.get_class
    path: simfire.sim.simulation.FireSimulation
  config_dict: ${simulation.simfire}

movements: [none, up, down, left, right]
interactions: [none, fireline]
attributes: [fire_map, elevation, w_0, sigma, delta, M_x]
normalized_attributes: [elevation]
# For now, assume that agent speed is the same for all agents.
agent_speed: 4
num_agents: 3
agent_initialization_cls:
  _target_: hydra.utils.get_class
  path: simharness2.agents.FixedPositionAgentInitializer
agent_initialization_kwargs:
  agent_pos: [[0, 64], [127, 64], [64, 127]]

# Defines the class that will be used to monitor and track `ReactiveHarness`.
harness_analytics_partial:
  _target_: simharness2.analytics.harness_analytics.ReactiveHarnessAnalytics
  _partial_: true
  # Defines the class that will be used to monitor and track `FireSimulation`.
  sim_analytics_partial:
    _target_: simharness2.analytics.simulation_analytics.FireSimulationAnalytics
    _partial_: true
    # Defines the class that will be used to monitor and track agent behavior.
    agent_analytics_partial:
      _target_: simharness2.analytics.agent_analytics.ReactiveAgentAnalytics
      _partial_: true
      movement_types: ${....movements}
      interaction_types: ${....interactions}
# Defines the class that will be used to perform reward calculation at each timestep.
reward_init_cfg:
  reward_cls:
    _target_: hydra.utils.get_class
    path: simharness2.rewards.base_reward.SimpleReward
  kwargs: null

action_space_cls:
  _target_: hydra.utils.get_class
  path: gymnasium.spaces.Discrete
